import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from surprise import Reader, Dataset, KNNBasic
import streamlit as st
import matplotlib as plt
import plotly.express as px


st.header('ğŸ“–ë„ì„œì¶”ì²œì•Œê³ ë¦¬ì¦˜')


st.sidebar.markdown("""
    ## ë„ì„œ ì¤‘ì‹¬ ë¶„ì„
    - [part 1. í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ](#part-1-book)
    - [part 2. ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ](#part-2-book)
    - [part 3. í–‰ë ¬ ì¸ìˆ˜ë¶„í•´  ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ](#part-3-book)
    - [part 4. ë”¥ ëŸ¬ë‹ ëª¨ë¸ ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ](#part-4-book)
    - [part 5. ì•™ìƒë¸” ê¸°ë²•ì„ ì‚¬ìš©í•œ ì¶”ì²œ ì‹œìŠ¤í…œ](#part-5-book)
    - [part 6. í•˜ì´í¼ë§ˆë¼ë¯¸í„° ìµœì í™”ë¥¼ í†µí•œ ì¶”ì²œ ì‹œìŠ¤í…œ](#part-6-book)
""")
st.write('')
st.write("""
- ì¶œíŒì‚¬ë‚˜ ë„ì„œ ê¸°ì—…ì˜ ì…ì¥ì—ì„œ ë„ì„œ í‰ì ì„ í™œìš©í•œ ë¶„ì„ì´ë‹¤. ì¶œíŒì‚¬/ë„ì„œê¸°ì—…ì´ ê°€ì§€ê³  ìˆëŠ” ê³ ê° ë°ì´í„°ì™€ í‰ì  ë“±ì„ í†µí•´ ì¶œíŒì‚¬/ë„ì„œê¸°ì—…ì˜ ë°ì´í„°ê°€ ê³ ê°ì˜ í‰ì ì— ì–´ë– í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê³ ê°ì˜ ì„ í˜¸ë„ë¥¼ ë¶„ì„í•œë‹¤.
""")
st.write('')
st.write('')



js = "window.scrollTo(0, document.getElementById('part-1-book').offsetTop);"

    
st.markdown("<h3 id='part-1-book'>âœ…Part 1. í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ</h3>", unsafe_allow_html=True)

st.write("""
âœ” ì‚¬ìš©ìê¸°ë°˜ í˜‘ì—…í•„í„°ë§
""")

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('data/TRAIN.csv')

# í‰ì ì´ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
train = train[train['Book-Rating'] >= 4]

# ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
pivot_data = train.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating', fill_value=0)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
cos_sim = cosine_similarity(pivot_data)

# ì‚¬ìš©ì ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ (KNNBasic) ëª¨ë¸ êµ¬ì¶•
reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(train[['User-ID', 'Book-Title', 'Book-Rating']], reader)
trainset = data.build_full_trainset()
sim_options = {'name': 'cosine', 'user_based': True}
user_based_cf = KNNBasic(sim_options=sim_options)
user_based_cf.fit(trainset)

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ì±…ê³¼ ìœ ì‚¬í•œ ì±… 5ê°œ ì¶”ì²œ
def recommend_books(book_title):
    book_rating = pivot_data[book_title]
    similar_books_index = np.unique(np.argsort(book_rating)[-6:-1])
    similar_books = list(pivot_data.columns[similar_books_index])
    recommended_books = []
    for book in similar_books:
        _, _, _, est, _ = user_based_cf.predict(uid=book, iid=book_title)
        if est >= 4.0:
            recommended_books.append(book)
    return recommended_books


# Streamlit ì•± êµ¬ì„±
st.title('Book Recommender')
book_title = st.text_input('Enter a book title')
if book_title in pivot_data.columns:
    recommended_books = recommend_books(book_title)
    if len(recommended_books) > 0:
        st.write('Recommended books:')
        for book in recommended_books:
            st.write('- ' + book)
    else:
        st.write('No recommended books')
else:
    st.write('Enter a valid book title')
    
    
st.write("""
âœ” ì•„ì´í…œê¸°ë°˜ í˜‘ì—…í•„í„°ë§
""")

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('data/TRAIN.csv')

# í‰ì ì´ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
train = train[train['Book-Rating'] >= 4]

# ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
pivot_data = train.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating', fill_value=0)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
cos_sim = cosine_similarity(pivot_data.T)

# ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ (KNNBasic) ëª¨ë¸ êµ¬ì¶•
reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(train[['User-ID', 'Book-Title', 'Book-Rating']], reader)
trainset = data.build_full_trainset()
sim_options = {'name': 'cosine', 'user_based': False}
item_based_cf = KNNBasic(sim_options=sim_options)
item_based_cf.fit(trainset)

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ì±…ê³¼ ìœ ì‚¬í•œ ì±… 5ê°œ ì¶”ì²œ
def recommend_books(book_title):
    book_rating = pivot_data[book_title]
    similar_books_index = np.unique(np.argsort(book_rating)[-6:-1])
    similar_books = list(pivot_data.columns[similar_books_index])
    recommended_books = []
    for book in similar_books:
        _, _, _, est, _ = user_based_cf.predict(uid=book, iid=book_title)
        if est >= 4.0:
            recommended_books.append(book)
    return recommended_books


# Streamlit ì•± êµ¬ì„±
st.title('Book Recommender')
book_title = st.text_input('Enter a book title', key='book_input')
if book_title in pivot_data.columns:
    recommended_books = recommend_books(book_title)
    if len(recommended_books) > 0:
        st.write('Recommended books:')
        for book in recommended_books:
            st.write('- ' + book)
    else:
        st.write('No recommended books')
else:
    st.write('Enter a valid book title')

js = "window.scrollTo(0, document.getElementById('part-2-book').offsetTop);"

    
st.markdown("<h3 id='part-2-book'>âœ…Part 2. ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ</h3>", unsafe_allow_html=True)

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('data/TRAIN.csv')

# í‰ì ì´ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
train = train[train['Book-Rating'] >= 4]

# ë°ì´í„° ì „ì²˜ë¦¬: ì±… ì œëª©ì˜ ì¤‘ë³µ ì œê±° ë° TF-IDF ë²¡í„°í™”
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
book_titles = train['Book-Title'].unique()
tfidf_matrix = tfidf_vectorizer.fit_transform(book_titles)
cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ì±…ê³¼ ìœ ì‚¬í•œ ì±… 5ê°œ ì¶”ì²œ
def recommend_books(book_title):
    book_rating = pivot_data[book_title]
    similar_books_index = np.unique(np.argsort(book_rating)[-6:-1])
    similar_books = list(pivot_data.columns[similar_books_index])
    recommended_books = []
    for book in similar_books:
        _, _, _, est, _ = user_based_cf.predict(uid=book, iid=book_title)
        if est >= 4.0:
            recommended_books.append(book)
    return recommended_books

# Streamlit ì•± êµ¬ì„±
st.title('Book Recommender')
book_title = st.text_input('Enter a book title', key='book_title_input')
if book_title in book_titles:
    recommended_books = recommend_books(book_title)
    st.write('Recommended books:')
    for book in recommended_books:
        st.write('- ' + book)
else:
    st.write('Enter a valid book title')

js = "window.scrollTo(0, document.getElementById('part-3-book').offsetTop);"

st.markdown("<h3 id='part-3-book'>âœ…Part 3. í–‰ë ¬ ì¸ìˆ˜ë¶„í•´  ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ</h3>", unsafe_allow_html=True)

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from surprise import Reader, Dataset
from surprise import SVD
import streamlit as st

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('data/TRAIN.csv')

# í‰ì ì´ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
train = train[train['Book-Rating'] >= 4]

# ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
pivot_data = train.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating', fill_value=0)

# SVD ëª¨ë¸ êµ¬ì¶•
reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(train[['User-ID', 'Book-Title', 'Book-Rating']], reader)
trainset = data.build_full_trainset()
svd_model = SVD(n_factors=20, reg_all=0.02)
svd_model.fit(trainset)

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ì±…ê³¼ ìœ ì‚¬í•œ ì±… 5ê°œ ì¶”ì²œ
def recommend_books(book_title):
    book_rating = pivot_data[book_title]
    similar_books_index = np.unique(np.argsort(cos_sim[pivot_data.columns.get_loc(book_title)])[-6:-1])
    similar_books = list(pivot_data.columns[similar_books_index])
    recommended_books = []
    for book in similar_books:
        _, _, _, est, _ = svd_model.predict(uid=book_title, iid=book)
        if est >= 4.0:
            recommended_books.append(book)
    return recommended_books

# Streamlit ì•± êµ¬ì„±
st.title('Book Recommender')
book_title = st.text_input('Enter a book title', key='input')
if book_title in pivot_data.columns:
    recommended_books = recommend_books(book_title)
    if len(recommended_books) > 0:
        st.write('Recommended books:')
        for book in recommended_books:
            st.write('- ' + book)
    else:
        st.write('No recommended books')
else:
    st.write('Enter a valid book title')

js = "window.scrollTo(0, document.getElementById('part-4-book').offsetTop);"

st.markdown("<h3 id='part-4-book'>âœ…Part 4. ë”¥ ëŸ¬ë‹ ëª¨ë¸ ê¸°ë°˜ì˜ ì¶”ì²œ ì‹œìŠ¤í…œ</h3>", unsafe_allow_html=True)

js = "window.scrollTo(0, document.getElementById('part-5-book').offsetTop);"

import pandas as pd
import numpy as np
import tensorflow as tf
import pickle

import pandas as pd
import numpy as np
import tensorflow as tf
import pickle

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('data/TRAIN.csv')

# í‰ì ì´ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
train = train[train['Book-Rating'] >= 4]

# ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
pivot_data = train.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating', fill_value=0)

# ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(pivot_data.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(pivot_data.shape[1])
])
model.compile(loss='mse', optimizer='adam')
model.fit(pivot_data.values, pivot_data.values, epochs=10, batch_size=64)

# ëª¨ë¸ ì €ì¥
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

# ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
def process_input_data(input_data):
    processed_data = np.zeros((1, pivot_data.shape[1]))
    for title, rating in input_data.items():
        if title in pivot_data.columns:
            processed_data[0, pivot_data.columns.get_loc(title)] = rating
    return processed_data

# ëª¨ë¸ ì˜ˆì¸¡
def predict_books(input_data):
    processed_data = process_input_data(input_data)
    predictions = model.predict(processed_data)
    recommended_books = pivot_data.columns[np.argsort(-predictions[0])][:10]
    return recommended_books

# ê²°ê³¼ ë°˜í™˜
input_data = {'The Da Vinci Code': 



st.markdown("<h3 id='part-5-book'>âœ…Part 5. ì•™ìƒë¸” ê¸°ë²•ì„ ì‚¬ìš©í•œ ì¶”ì²œ ì‹œìŠ¤í…œ</h3>", unsafe_allow_html=True)



js = "window.scrollTo(0, document.getElementById('part-6-book').offsetTop);"

st.markdown("<h3 id='part-6-book'>âœ…Part 6. í•˜ì´í¼ë§ˆë¼ë¯¸í„° ìµœì í™”ë¥¼ í†µí•œ ì¶”ì²œ ì‹œìŠ¤í…œ</h3>", unsafe_allow_html=True)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Dot
from tensorflow.keras.models import Model
from tensorflow.keras.wrappers.scikit_learn import KerasRegressor

def create_pivot_data():
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    train = pd.read_csv('data/TRAIN.csv')

    # í‰ì ì´ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ ì‚¬ìš©
    train = train[train['Book-Rating'] >= 4]

    # ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
    pivot_data = train.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating', fill_value=0)

    return pivot_data

def create_model(embedding_size=10, optimizer='adam'):
    # ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
    pivot_data = create_pivot_data()

    # í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬
    train_data, test_data = train_test_split(pivot_data, test_size=0.2)

    # ëª¨ë¸ êµ¬ì„±
    num_users, num_items = len(pivot_data), len(pivot_data.columns)
    input_layer = Input(shape=(1,))
    embedding_layer = Embedding(num_users, embedding_size)(input_layer)
    flatten_layer = Flatten()(embedding_layer)
    output_layer = Dense(num_items, activation='relu')(flatten_layer)
    dot_layer = Dot(axes=1)([output_layer, embedding_layer])
    model = Model(inputs=[input_layer], outputs=[dot_layer])
    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])

    return model

    def grid_search():
    # ëª¨ë¸ ìƒì„± í•¨ìˆ˜ë¥¼ KerasRegressorë¡œ ë˜í•‘
    model = KerasRegressor(build_fn=create_model, verbose=0)

    # ê·¸ë¦¬ë“œì„œì¹˜ë¥¼ ìˆ˜í–‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ë“¤
    embedding_size = [10, 20, 30]
    optimizer = ['adam', 'sgd']

    # ê·¸ë¦¬ë“œì„œì¹˜ë¥¼ ìˆ˜í–‰í•  ë§¤ê°œë³€ìˆ˜ ê·¸ë¦¬ë“œ
    param_grid = dict(embedding_size=embedding_size, optimizer=optimizer)

    # ê·¸ë¦¬ë“œì„œì¹˜ ìˆ˜í–‰
    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)
    grid_result = grid.fit(X=np.array(train_data.index), y=train_data.values)

    # ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ í‰ê°€ ì§€í‘œ ì¶œë ¥
    print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
    means = grid_result.cv_results_['mean_test_score']
    stds = grid_result.cv_results_['std_test_score']
    params = grid_result.cv_results_['params']
    for mean, stdev, param in zip(means, stds, params):
        print("%f (%f) with: %r" % (mean, stdev

